{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from transformers import BertModel, BertConfig, BertTokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def positional_encoding(positions, d):\n",
    "    \"\"\"\n",
    "    Precomputes a matrix with all the positional encodings \n",
    "    \n",
    "    Arguments:\n",
    "        positions (int) -- Maximum number of positions to be encoded \n",
    "        d (int) -- Encoding size \n",
    "    \n",
    "    Returns:\n",
    "        pos_encoding -- (1, position, d_model) A matrix with the positional encodings\n",
    "    \"\"\"\n",
    "    # initialize a matrix angle_rads of all the angles \n",
    "    pos = torch.arange(positions).unsqueeze(1)\n",
    "    ks = torch.arange(d).unsqueeze(0)\n",
    "    angle_rads = get_angles(pos, ks, d)\n",
    "\n",
    "    # apply sin to even indices in the array; 2i\n",
    "    # apply cos to odd indices in the array; 2i+1\n",
    "    for k in range(d):\n",
    "        if k % 2 == 0:\n",
    "            angle_rads[:, k] = torch.sin(angle_rads[:, k])\n",
    "        else:\n",
    "            angle_rads[:, k] = torch.cos(angle_rads[:, k])\n",
    "    \n",
    "    pos_encoding = angle_rads.unsqueeze(0)\n",
    "    \n",
    "    return pos_encoding.float()\n",
    "\n",
    "def get_angles(pos, ks, d):\n",
    "    angle_rates = 1 / torch.pow(10000, (2 * (ks // 2)) / torch.tensor(d).float())\n",
    "    return pos.float() * angle_rates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DecoderLayer(nn.Module):\n",
    "    def __init__(self, embedding_dim, num_heads, fully_connected_dim, dropout_rate=0.1, layernorm_eps=1e-6):\n",
    "        super(DecoderLayer, self).__init__()\n",
    "\n",
    "        self.mha1 = nn.MultiheadAttention(embed_dim=embedding_dim, num_heads=num_heads, dropout=dropout_rate)\n",
    "        self.mha2 = nn.MultiheadAttention(embed_dim=embedding_dim, num_heads=num_heads, dropout=dropout_rate)\n",
    "        self.ffn = nn.Sequential(\n",
    "            nn.Linear(embedding_dim, fully_connected_dim),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(fully_connected_dim, embedding_dim)\n",
    "        )\n",
    "        self.layernorm1 = nn.LayerNorm(embedding_dim, eps=layernorm_eps)\n",
    "        self.layernorm2 = nn.LayerNorm(embedding_dim, eps=layernorm_eps)\n",
    "        self.layernorm3 = nn.LayerNorm(embedding_dim, eps=layernorm_eps)\n",
    "        self.dropout_ffn = nn.Dropout(dropout_rate)\n",
    "\n",
    "    def forward(self, x, enc_output, padding_mask):\n",
    "        mha_output1 = self.mha1(x, x, x)\n",
    "        out1 = self.layernorm1(x + mha_output1)\n",
    "\n",
    "        mha_output2 = self.mha2(out1, enc_output, enc_output, key_padding_mask=padding_mask)\n",
    "        out2 = self.layernorm2(out1 + mha_output2)\n",
    "\n",
    "        ffn_output = self.ffn(out2)\n",
    "        ffn_output = self.dropout_ffn(ffn_output)\n",
    "\n",
    "        out3 = self.layernorm3(out2 + ffn_output)\n",
    "\n",
    "        return out3\n",
    "\n",
    "class Decoder(nn.Module):\n",
    "    def __init__(self, num_layers, embedding_dim, num_heads, fully_connected_dim, target_vocab_size,\n",
    "                 maximum_position_encoding, dropout_rate=0.1, layernorm_eps=1e-6):\n",
    "        super(Decoder, self).__init__()\n",
    "\n",
    "        self.embedding_dim = embedding_dim\n",
    "        self.num_layers = num_layers\n",
    "\n",
    "        self.embedding = nn.Embedding(target_vocab_size, embedding_dim)\n",
    "        self.pos_encoding = positional_encoding(maximum_position_encoding, embedding_dim)\n",
    "\n",
    "        self.dec_layers = nn.ModuleList([\n",
    "            DecoderLayer(embedding_dim, num_heads, fully_connected_dim, dropout_rate, layernorm_eps)\n",
    "            for _ in range(num_layers)\n",
    "        ])\n",
    "        self.dropout = nn.Dropout(dropout_rate)\n",
    "\n",
    "    def forward(self, x, enc_output, padding_mask):\n",
    "        seq_len = x.size(1)\n",
    "\n",
    "        x = self.embedding(x)\n",
    "        x += self.pos_encoding[:, :seq_len, :]  # Add positional encoding\n",
    "        x *= torch.sqrt(torch.tensor(self.embedding_dim, dtype=torch.float32))\n",
    "        x = self.dropout(x)\n",
    "\n",
    "        for i in range(self.num_layers):\n",
    "            x = self.dec_layers[i](x, enc_output, padding_mask)\n",
    "\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from transformers import BertModel, BertConfig\n",
    "\n",
    "class Encoder(nn.Module):\n",
    "    def __init__(self, bert_model, maximum_position_encoding, dropout_rate=0.1):\n",
    "        super(Encoder, self).__init__()\n",
    "\n",
    "        self.bert = bert_model\n",
    "        self.config = bert_model.config  # Extract BERT configuration\n",
    "\n",
    "        self.pos_encoding = positional_encoding(maximum_position_encoding, self.config.hidden_size)\n",
    "        self.dropout = nn.Dropout(dropout_rate)\n",
    "\n",
    "    def forward(self, x, padding_mask):\n",
    "        \"\"\"\n",
    "        Forward pass for the Encoder\n",
    "        \n",
    "        Arguments:\n",
    "            x -- Tensor of shape (batch_size, input_seq_len, hidden_size)\n",
    "                An array of the indexes of the words in the input sentence\n",
    "            padding_mask -- Boolean mask to ensure that the padding is not \n",
    "                            treated as part of the input\n",
    "        Returns:\n",
    "            out -- Tensor of shape (batch_size, input_seq_len, hidden_size)\n",
    "        \"\"\"\n",
    "        # Get BERT embeddings\n",
    "        bert_output = self.bert(x, attention_mask=~padding_mask)[0]\n",
    "        \n",
    "        # Apply positional encoding\n",
    "        seq_len = bert_output.size(1)\n",
    "        pos_encoding = self.pos_encoding[:, :seq_len, :]\n",
    "        bert_output += pos_encoding\n",
    "\n",
    "        # Apply dropout\n",
    "        out = self.dropout(bert_output)\n",
    "\n",
    "        return out\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Transformer(nn.Module):\n",
    "    def __init__(self, bert_model, num_layers, embedding_dim, num_heads, fully_connected_dim, target_vocab_size,\n",
    "                 maximum_position_encoding,\n",
    "                 dropout_rate=0.1, layernorm_eps=1e-6):\n",
    "        super(Transformer, self).__init__()\n",
    "\n",
    "        self.encoder = Encoder(bert_model, dropout_rate=dropout_rate, maximum_position_encoding=maximum_position_encoding)\n",
    "\n",
    "        self.decoder = Decoder(num_layers=num_layers, \n",
    "                               embedding_dim=embedding_dim,\n",
    "                               num_heads=num_heads,\n",
    "                               fully_connected_dim=fully_connected_dim,\n",
    "                               target_vocab_size=target_vocab_size,\n",
    "                               maximum_position_encoding=maximum_position_encoding,\n",
    "                               dropout_rate=dropout_rate,\n",
    "                               layernorm_eps=layernorm_eps)\n",
    "\n",
    "        self.final_layer = nn.Linear(fully_connected_dim, target_vocab_size)\n",
    "        self.softmax = nn.Softmax(dim=-1)\n",
    "    \n",
    "    def forward(self, input_sentence, output_sentence, enc_padding_mask, dec_padding_mask):\n",
    "        enc_output = self.encoder(input_sentence, enc_padding_mask)\n",
    "        dec_output = self.decoder(output_sentence, enc_output, dec_padding_mask)\n",
    "        \n",
    "        final_output = self.final_layer(dec_output)\n",
    "        final_output = self.softmax(final_output)\n",
    "\n",
    "        return final_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertModel were not initialized from the model checkpoint at Geotrend/bert-base-uk-cased and are newly initialized: ['bert.pooler.dense.bias', 'bert.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "def create_transformer_model(bert_model_name, num_layers, fully_connected_dim, num_heads,\n",
    "                             maximum_position_encoding=1000,\n",
    "                             dropout_rate=0.1, layernorm_eps=1e-6):\n",
    "    # Load pretrained BERT model\n",
    "    bert_model = BertModel.from_pretrained(bert_model_name)\n",
    "    tokenizer = BertTokenizer.from_pretrained(bert_model_name)\n",
    "\n",
    "    # Extract relevant parameters from BERT configuration\n",
    "    embedding_dim = bert_model.config.hidden_size\n",
    "    target_vocab_size = len(tokenizer.get_vocab())\n",
    "\n",
    "    # Create Transformer model\n",
    "    transformer_model = Transformer(\n",
    "        bert_model=bert_model,\n",
    "        num_layers=num_layers,\n",
    "        embedding_dim=embedding_dim,\n",
    "        num_heads=num_heads,\n",
    "        fully_connected_dim=fully_connected_dim,\n",
    "        target_vocab_size=target_vocab_size,\n",
    "        maximum_position_encoding=maximum_position_encoding,\n",
    "        dropout_rate=dropout_rate,\n",
    "        layernorm_eps=layernorm_eps\n",
    "    )\n",
    "\n",
    "    return transformer_model, tokenizer\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "bert_model_name = 'Geotrend/bert-base-uk-cased'\n",
    "num_layers = 6  # Adjust as needed\n",
    "fully_connected_dim = 512  # Adjust as needed\n",
    "num_heads = 8\n",
    "\n",
    "transformer_model = create_transformer_model(\n",
    "    bert_model_name, num_layers, fully_connected_dim, num_heads\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-25 22:23:34 WARNING: Language uk package default expects mwt, which has been added\n",
      "2023-11-25 22:23:34 INFO: Loading these models for language: uk (Ukrainian):\n",
      "=======================\n",
      "| Processor | Package |\n",
      "-----------------------\n",
      "| tokenize  | iu      |\n",
      "| mwt       | iu      |\n",
      "=======================\n",
      "\n",
      "2023-11-25 22:23:34 INFO: Using device: cuda\n",
      "2023-11-25 22:23:34 INFO: Loading: tokenize\n",
      "2023-11-25 22:23:34 INFO: Loading: mwt\n",
      "2023-11-25 22:23:34 INFO: Done loading processors!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Complete Vocabulary: {'<pad>': 0, '<unk>': 1, 'Привіт': 2, ',': 3, 'світе': 4, '!': 5, 'Це': 6, 'приклад': 7, 'тексту': 8, 'для': 9, 'обробки': 10, '.': 11}\n",
      "Processed Lines:\n",
      "tensor([[ 2,  3,  4,  5,  6,  7,  8,  9, 10, 11]])\n",
      "Mask:\n",
      "tensor([[1., 1., 1., 1., 1., 1., 1., 1., 1., 1.]])\n"
     ]
    }
   ],
   "source": [
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
